{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "filled-luxembourg",
   "metadata": {},
   "source": [
    "# Importing libraries and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-growth",
   "metadata": {},
   "source": [
    "# Creating Dataset\n",
    "\n",
    "- Dataset was first convert to csv file with 2 columns Tags and Word\n",
    "- File was imported, Cleaned and Saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset.csv\")\n",
    "dataset = dataset.dropna()\n",
    "dataset.to_csv(\"dataset.csv\", index = False)\n",
    "\n",
    "dataset = pd.read_csv(\"dataset_test.csv\")\n",
    "\n",
    "dataset = dataset.dropna()\n",
    "dataset.to_csv(\"dataset_test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-prior",
   "metadata": {},
   "source": [
    "# Creating data and labels\n",
    "\n",
    "- Dataset was divided 4 file\n",
    "1. X_train : Contains Training Words\n",
    "2. X_test : Contains Training Tags\n",
    "3. Y_train : Contains Test Words\n",
    "4. Y_test : Contains Test Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading data...')\n",
    "\n",
    "x_train = pd.read_csv(\"x_train.csv\")\n",
    "x_train[\"Word\"] = x_train[\"Word\"].apply(str)\n",
    "\n",
    "x_test = pd.read_csv(\"x_test.csv\")\n",
    "x_test[\"Word\"] = x_test[\"Word\"].apply(str)\n",
    "\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-college",
   "metadata": {},
   "source": [
    "# Label Encoding\n",
    "\n",
    "- Tags are labelled using label encoder and one hot encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "\n",
    "y_train[\"Tag\"] = labelencoder.fit_transform(y_train[\"Tag\"])\n",
    "y_test[\"Tag\"] = labelencoder.transform(y_test[\"Tag\"])\n",
    "\n",
    "onehotencoder = OneHotEncoder() \n",
    "\n",
    "Y_train = onehotencoder.fit_transform(y_train[\"Tag\"].values.reshape(-1,1)).toarray()\n",
    "Y_test = onehotencoder.transform(y_test[\"Tag\"].values.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-headset",
   "metadata": {},
   "source": [
    "# Dataset Preprocessing\n",
    "\n",
    "- Tokenisation of words and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 30000\n",
    "maxlen = 1\n",
    "batch_size = 32\n",
    "\n",
    "x_train = x_train['Word'].fillna('').tolist()\n",
    "\n",
    "x_test = x_test['Word'].fillna('').tolist()\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 200000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-prison",
   "metadata": {},
   "source": [
    "# Building Model\n",
    "\n",
    "- Building LSTM model using Tensorflow and Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2,return_sequences=True))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(17, activation='softmax'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bulgarian-royalty",
   "metadata": {},
   "source": [
    "# Training and Predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extreme-bidding",
   "metadata": {},
   "source": [
    "print('Train...')\n",
    "model.fit(x_train, Y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=10,\n",
    "          validation_data=(x_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-speaking",
   "metadata": {},
   "source": [
    "# Evaluation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "score, acc = model.evaluate(pred, Y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-filling",
   "metadata": {},
   "source": [
    "# Saving model and other objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"rnn.hdf5\")\n",
    "\n",
    "with open('labelencoder', 'wb') as f:\n",
    "    pickle.dump(labelencoder, f)\n",
    "    \n",
    "with open('onehotencoder', 'wb') as f:\n",
    "    pickle.dump(onehotencoder, f)\n",
    "    \n",
    "with open('tokenizer', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
